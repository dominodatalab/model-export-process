{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3483ed8c-cf80-4cd3-b949-f37af5b7074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import mlflow\n",
    "from mlflow.client import MlflowClient\n",
    "from mlflow.models import infer_signature, ModelSignature\n",
    "from mlflow.types import Schema, ColSpec\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223b548-5473-4257-b163-37e89a19bd5c",
   "metadata": {},
   "source": [
    "### Model Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6648eb5-aff9-498a-b9bd-aa00d4c5351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = datasets.load_breast_cancer()\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, \n",
    "                                                    data.target,\n",
    "                                                    stratify=data.target)\n",
    "# Instantiating and fitting the model\n",
    "model = LogisticRegression(max_iter=1000)            \n",
    "model.fit(X=X_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c049a3-93d2-40cc-b7d8-8edb0b7fa4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting train features into a DataFrame\n",
    "X_train_df = pd.DataFrame(data=X_train, columns=data.feature_names)\n",
    "\n",
    "# Inferring the input signature\n",
    "signature = infer_signature(model_input=X_train_df, \n",
    "                           model_output=model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800392af-b7b6-46a0-8531-5046e5700870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an input schema for the breast cancer dataset\n",
    "input_schema = Schema(inputs=[ColSpec(type=\"double\", name=feature_name) \n",
    "                              for feature_name in data.feature_names])\n",
    "\n",
    "# Creating an output schema for the breast cancer dataset\n",
    "output_schema = Schema(inputs=[ColSpec(\"double\")])\n",
    "\n",
    "# Creating a signature from our schemas\n",
    "#signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941984f4-9c43-44f2-90e6-077f7f38b4eb",
   "metadata": {},
   "source": [
    "### Save the model locally to /mnt/mymodel\n",
    "\n",
    "This is just to show how you can save and run the model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e92a355-dca9-4ac6-9539-fae173922966",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "folder_path = \"/tmp/mymodel\"\n",
    "if os.path.exists(folder_path):\n",
    "        if os.path.isdir(folder_path):\n",
    "            shutil.rmtree(folder_path)\n",
    "            \n",
    "# Saving the model. Note the path. This will save the model under /mnt/model\n",
    "input_example = X_train_df.iloc[:1]\n",
    "mlflow.sklearn.save_model(sk_model=model, \n",
    "                          path=folder_path, \n",
    "                          signature=signature,\n",
    "                          input_example=input_example)\n",
    "##Verify that is looks good\n",
    "os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879eef6-a744-4b09-b42e-c333a1a6a33f",
   "metadata": {},
   "source": [
    "### Review the output\n",
    "\n",
    "Especially take a look at the `requirements.txt` and the yaml files and the `requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b9dca-756c-4459-b58e-a45c3030944a",
   "metadata": {},
   "source": [
    "### Run the locally saved model\n",
    "\n",
    "This is a way all models should be run if you want them to be portable. This is the industry\n",
    "standard MLFLOW based mechanism to load and run models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab9dc0a-afd3-44ea-a0bc-8e1b6ff3374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run the locally saved model\n",
    "import os\n",
    "import pandas as pd\n",
    "def predict(model_uri,features):\n",
    "    loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "    return loaded_model.predict(features)\n",
    "cwd = os.getcwd()\n",
    "d = pd.read_json(f'{cwd}/client/features.json', orient='records', lines=True)    \n",
    "predict(folder_path,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c323a-3d71-46c4-aa16-634c9b686783",
   "metadata": {},
   "source": [
    "### Now we register this model with Domino Experiment Manager\n",
    "\n",
    "1. Create an experiment with a meaningful name\n",
    "2. Create a registered model name\n",
    "3. Finally register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529751e7-a72a-4f87-ba5f-5660333c49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "experiment_name = \"pltr-foundry-export-example\"\n",
    "model_name = \"pltr_foundry_model\" \n",
    "try:\n",
    "    client.create_registered_model(model_name)\n",
    "except:\n",
    "    print('Model already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f4ace-df69-4639-8cdf-b21a1a38de98",
   "metadata": {},
   "source": [
    "## The Most Important Part - Model Registration\n",
    "\n",
    "Pay close attention to not just the models that are being registered. But also the additional files we are choosing to add to the model registry. We can add anything our final image in our \n",
    "final execution environment will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45be92f5-fd89-44f1-8f6e-2e4000868e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model as an artifact in a run\n",
    "from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "\n",
    "run_id=''\n",
    "##Specify Dependencies implicitly\n",
    "with mlflow.start_run() as run:\n",
    "    # Obtaining the ID of this run\n",
    "    run_id = run.info.run_id\n",
    "    # Logging our model\n",
    "    model_folder = 'mymodel'\n",
    "    model_client_folder = 'client'\n",
    "    model_templates_folder = 'templates'\n",
    "    model_entry_point = 'python'\n",
    "    model_command_line = 'client/execute_model.py'\n",
    "    model_info = mlflow.sklearn.log_model(sk_model=model, \n",
    "                             artifact_path=model_folder,  \n",
    "                             signature=signature,\n",
    "                             input_example=input_example)\n",
    "    ##Note these artifacts being logged.\n",
    "    mlflow.log_artifact(f'{cwd}/client/model.json',model_client_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/client/features.json',model_client_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/client/example_predict.py',model_client_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/client/execute_model.py',model_client_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/templates/Dockerfile.template',model_templates_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/templates/create_docker_image.sh.template',model_templates_folder)\n",
    "\n",
    "'''\n",
    "Tags are a way of passing metadata to the model version client. In our case it will be the \n",
    "external program that will download these model versions and publish images to foundry\n",
    "\n",
    "'''\n",
    "my_tags={}\n",
    "#The download client will ignore models which do not have this flag set\n",
    "#This is how a Model Engineer tells the external program that this model is intended to be\n",
    "#registered to foundry\n",
    "#my_tags['EXTERNAL_TARGET_PLTR_FOUNDRY']='True'\n",
    "#Foundry URL goes here. Add additional tags as needed. DO NOT ADD TOKENS OR CREDENTIALS\n",
    "#The client program is supposed to get them from some SECRET STORE\n",
    "#my_tags['FOUNDRY_URL']='quay.io/domino'\n",
    "my_tags['MODEL_FOLDER']='mymodel'\n",
    "my_tags['MODEL_CLIENT_FOLDER']='client'\n",
    "my_tags['MODEL_ENTRY_POINT']='python'\n",
    "my_tags['MODEL_EXECUTE_PATH']='client/execute_model.py'\n",
    "\n",
    "model_src = RunsArtifactRepository.get_underlying_uri(f\"runs:/{run_id}/\")\n",
    "mv = client.create_model_version(model_name, model_src, run_id,tags=my_tags)\n",
    "print(\"Name: {}\".format(mv.name))\n",
    "print(\"Version: {}\".format(mv.version))\n",
    "print(\"Description: {}\".format(mv.description))\n",
    "print(\"Status: {}\".format(mv.status))\n",
    "print(\"Stage: {}\".format(mv.current_stage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9920bb-14c7-4a91-8241-5a568153fc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now Launch the remote build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a55a16b-c1a0-418d-988e-f0403c3c590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['REGISTRY_URL']='xxx-xx-registry.palantirfoundry.com'\n",
    "os.environ['REGISTRY_USER']='<REGISTRY_USER>'\n",
    "os.environ['REGISTRY_TOKEN']='REGISTRY_TOKEN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8fe2d0-4d1c-4b10-b2b8-eaf7ead213f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "mv = client.create_model_version(model_name, model_src, run_id,tags=my_tags)\n",
    "model_name=mv.name\n",
    "model_name=mv.name\n",
    "\n",
    "MLFLOW_TRACKING_URI='https://secureds53799.cs.domino.tech/'\n",
    "\n",
    "\n",
    "url = \"https://34.218.240.146:8443/build\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"model_name\": \"pltr_foundry_model\",\n",
    "  \"model_version\": \"19\"\n",
    "})\n",
    "headers = {\n",
    "  'MLFLOW_TRACKING_URI': MLFLOW_TRACKING_URI,\n",
    "  'DOMINO_USER_API_KEY': os.environ['DOMINO_USER_API_KEY'],\n",
    "  'DOMINO_RUN_ID': os.environ['DOMINO_RUN_ID'],\n",
    "  'REGISTRY_URL': os.environ['REGISTRY_URL'],\n",
    "  'REGISTRY_USER': os.environ['REGISTRY_USER'],\n",
    "  'REGISTRY_TOKEN': os.environ['REGISTRY_TOKEN'],\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload,verify=False)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead7042-8cb6-457a-a826-a82328f3a157",
   "metadata": {},
   "source": [
    "### Or run from the command line\n",
    "\n",
    "```\n",
    "export MODEL_NAME=foundry_model\n",
    "export MODEL_VERSION=7\n",
    "/tmp/local_models/${MODEL_NAME}/v${MODEL_VERSION}/example-prediction-code\n",
    "python example_predict.py foundry_model 7\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
