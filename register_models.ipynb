{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3483ed8c-cf80-4cd3-b949-f37af5b7074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import mlflow\n",
    "from mlflow.client import MlflowClient\n",
    "from mlflow.models import infer_signature, ModelSignature\n",
    "from mlflow.types import Schema, ColSpec\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3223b548-5473-4257-b163-37e89a19bd5c",
   "metadata": {},
   "source": [
    "### Model Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6648eb5-aff9-498a-b9bd-aa00d4c5351c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data\n",
    "data = datasets.load_breast_cancer()\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, \n",
    "                                                    data.target,\n",
    "                                                    stratify=data.target)\n",
    "# Instantiating and fitting the model\n",
    "model = LogisticRegression(max_iter=1000)            \n",
    "model.fit(X=X_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25c049a3-93d2-40cc-b7d8-8edb0b7fa4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting train features into a DataFrame\n",
    "X_train_df = pd.DataFrame(data=X_train, columns=data.feature_names)\n",
    "\n",
    "# Inferring the input signature\n",
    "signature = infer_signature(model_input=X_train_df, \n",
    "                           model_output=model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "800392af-b7b6-46a0-8531-5046e5700870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an input schema for the breast cancer dataset\n",
    "input_schema = Schema(inputs=[ColSpec(type=\"double\", name=feature_name) \n",
    "                              for feature_name in data.feature_names])\n",
    "\n",
    "# Creating an output schema for the breast cancer dataset\n",
    "output_schema = Schema(inputs=[ColSpec(\"double\")])\n",
    "\n",
    "# Creating a signature from our schemas\n",
    "#signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941984f4-9c43-44f2-90e6-077f7f38b4eb",
   "metadata": {},
   "source": [
    "### Save the model locally to /mnt/mymodel\n",
    "\n",
    "This is just to show how you can save and run the model locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e92a355-dca9-4ac6-9539-fae173922966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl',\n",
       " 'conda.yaml',\n",
       " 'python_env.yaml',\n",
       " 'input_example.json',\n",
       " 'requirements.txt',\n",
       " 'MLmodel']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "folder_path = \"/tmp/mymodel\"\n",
    "if os.path.exists(folder_path):\n",
    "        if os.path.isdir(folder_path):\n",
    "            shutil.rmtree(folder_path)\n",
    "            \n",
    "# Saving the model. Note the path. This will save the model under /mnt/model\n",
    "input_example = X_train_df.iloc[:1]\n",
    "mlflow.sklearn.save_model(sk_model=model, \n",
    "                          path=folder_path, \n",
    "                          signature=signature,\n",
    "                          input_example=input_example)\n",
    "##Verify that is looks good\n",
    "os.listdir(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879eef6-a744-4b09-b42e-c333a1a6a33f",
   "metadata": {},
   "source": [
    "### Review the output\n",
    "\n",
    "Especially take a look at the `requirements.txt` and the yaml files and the `requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b9dca-756c-4459-b58e-a45c3030944a",
   "metadata": {},
   "source": [
    "### Run the locally saved model\n",
    "\n",
    "This is a way all models should be run if you want them to be portable. This is the industry\n",
    "standard MLFLOW based mechanism to load and run models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ab9dc0a-afd3-44ea-a0bc-8e1b6ff3374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the locally saved model\n",
    "import os\n",
    "import pandas as pd\n",
    "def predict(model_uri,features):\n",
    "    loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "    return loaded_model.predict(features)\n",
    "cwd = os.getcwd()\n",
    "d = pd.read_json(f'{cwd}/features.json', orient='records', lines=True)    \n",
    "predict(folder_path,d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04c323a-3d71-46c4-aa16-634c9b686783",
   "metadata": {},
   "source": [
    "### Now we register this model with Domino Experiment Manager\n",
    "\n",
    "1. Create an experiment with a meaningful name\n",
    "2. Create a registered model name\n",
    "3. Finally register model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "529751e7-a72a-4f87-ba5f-5660333c49be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists\n"
     ]
    }
   ],
   "source": [
    "client = MlflowClient()\n",
    "mlflow.set_experiment('foundry-export-example')\n",
    "model_name = \"foundry_model\" \n",
    "try:\n",
    "    client.create_registered_model(model_name)\n",
    "except:\n",
    "    print('Model already exists')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672f4ace-df69-4639-8cdf-b21a1a38de98",
   "metadata": {},
   "source": [
    "## The Most Important Part - Model Registration\n",
    "\n",
    "Pay close attention to not just the models that are being registered. But also the additional files we are choosing to add to the model registry. We can add anything our final image in our \n",
    "final execution environment will need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45be92f5-fd89-44f1-8f6e-2e4000868e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:18: UserWarning: Distutils was imported before Setuptools, but importing Setuptools also replaces the `distutils` module in `sys.modules`. This may lead to undesirable behaviors or errors. To avoid these issues, avoid using distutils directly, ensure that setuptools is installed in the traditional way (e.g. not an editable install), and/or make sure that setuptools is always imported before distutils.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
      "2024/08/01 19:33:33 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: foundry_model, version 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: foundry_model\n",
      "Version: 34\n",
      "Description: \n",
      "Status: READY\n",
      "Stage: None\n"
     ]
    }
   ],
   "source": [
    "# Saving the model as an artifact in a run\n",
    "from mlflow.store.artifact.runs_artifact_repo import RunsArtifactRepository\n",
    "mlflow.set_experiment('foundry-export-example')\n",
    "\n",
    "\n",
    "run_id=''\n",
    "##Specify Dependencies implicitly\n",
    "with mlflow.start_run() as run:\n",
    "    # Obtaining the ID of this run\n",
    "    run_id = run.info.run_id\n",
    "    # Logging our model\n",
    "    model_folder = 'mymodel'\n",
    "    model_client_folder = 'client'\n",
    "    model_entry_point = 'python'\n",
    "    model_command_line = 'client/execute_model.py'\n",
    "    model_info = mlflow.sklearn.log_model(sk_model=model, \n",
    "                             artifact_path=model_folder,  \n",
    "                             signature=signature,\n",
    "                             input_example=input_example)\n",
    "    ##Note these artifacts being logged.\n",
    "    mlflow.log_artifact(f'{cwd}/client/features.json',model_client_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/client/example_predict.py',model_client_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/client/execute_model.py',model_client_folder)\n",
    "    mlflow.log_artifact(f'{cwd}/Dockerfile.template')\n",
    "    mlflow.log_artifact(f'{cwd}/create_docker_image.sh.template')\n",
    "\n",
    "'''\n",
    "Tags are a way of passing metadata to the model version client. In our case it will be the \n",
    "external program that will download these model versions and publish images to foundry\n",
    "\n",
    "'''\n",
    "my_tags={}\n",
    "#The download client will ignore models which do not have this flag set\n",
    "#This is how a Model Engineer tells the external program that this model is intended to be\n",
    "#registered to foundry\n",
    "my_tags['TARGET_PLTR_FOUNDRY']='True'\n",
    "#Foundry URL goes here. Add additional tags as needed. DO NOT ADD TOKENS OR CREDENTIALS\n",
    "#The client program is supposed to get them from some SECRET STORE\n",
    "my_tags['FOUNDRY_URL']='quay.io/domino'\n",
    "my_tags['MODEL_FOLDER']='mymodel'\n",
    "my_tags['MODEL_CLIENT_FOLDER']='client'\n",
    "my_tags['MODEL_ENTRY_POINT']='python'\n",
    "my_tags['MODEL_EXECUTE_PATH']='client/execute_model.py'\n",
    "\n",
    "model_src = RunsArtifactRepository.get_underlying_uri(f\"runs:/{run_id}/\")\n",
    "mv = client.create_model_version(model_name, model_src, run_id,tags=my_tags)\n",
    "print(\"Name: {}\".format(mv.name))\n",
    "print(\"Version: {}\".format(mv.version))\n",
    "print(\"Description: {}\".format(mv.description))\n",
    "print(\"Status: {}\".format(mv.status))\n",
    "print(\"Stage: {}\".format(mv.current_stage))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390f26c-9209-4735-80a8-92977fef8856",
   "metadata": {},
   "source": [
    "## Review the registered models\n",
    "1. Review the model artifacts for each of the two models above\n",
    "2. Specifically note the \"requirements.txt\"\n",
    "3. Ideally unless you know exactly what you are doing you should let mlflow decide on the dependencies. It pretty much takes all of the packages based on the model specification (pickle file) and adds them. This is usually right\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1013d732-11d8-45dc-a89e-ce8e05c20147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlflow-artifacts:/mlflow/7b60f02b5a1c47b1a5608c09a7330447/artifacts\n",
      "7b60f02b5a1c47b1a5608c09a7330447\n"
     ]
    }
   ],
   "source": [
    "### This is the implicit version\n",
    "print(model_src)\n",
    "print(run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092ab1d8-2389-4f6a-aab3-078a77f516bc",
   "metadata": {},
   "source": [
    "## Now imagine you are outside Domino and want to consume this model for prediction\n",
    "\n",
    "1. First you need to know the model name and version\n",
    "2. Use it to fetch the model version\n",
    "3. From the model version get the mlflow run_id\n",
    "4. Download the model locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542d616-52db-4c47-b343-c5b60ddf2542",
   "metadata": {},
   "source": [
    "## How do I get all models which have been tagged with foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fd1fd6f1-3bf8-4ab7-ac95-265a5fc0e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492760cf-0360-4dc8-8dae-ffe9f40660e7",
   "metadata": {},
   "source": [
    "### This is the part where we download the model, install the dependencies and invoke the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dd12bba6-e753-47b1-8595-68e3fd4d8eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ae37b7d85d40068e23d38f80b80c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/01 17:23:18 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker build --platform=linux/amd64 -f ./Dockerfile -t quay.io/foundry_model:15 .\n",
      "docker push quay.io/foundry_model:15 \n",
      "docker run quay.io/foundry_model:15\n",
      "\n",
      "\n",
      "File created at /tmp/local_models/foundry_model/v15/Dockerfile\n",
      "docker build --platform=linux/amd64 -f ./Dockerfile -t quay.io/foundry_model:15 .\n",
      "docker push quay.io/foundry_model:15 \n",
      "docker run quay.io/foundry_model:15\n",
      "\n",
      "\n",
      "File created at /tmp/local_models/foundry_model/v15/create_image.sh\n",
      "Model name foundry_model, and version 15 made prediction [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1\n",
      " 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1] for data      mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
      "0                   0.07871  ...        25.380          17.33   \n",
      "1                   0.05667  ...        24.990          23.41   \n",
      "2                   0.05999  ...        23.570          25.53   \n",
      "3                   0.09744  ...        14.910          26.50   \n",
      "4                   0.05883  ...        22.540          16.67   \n",
      "..                      ...  ...           ...            ...   \n",
      "564                 0.05623  ...        25.450          26.40   \n",
      "565                 0.05533  ...        23.690          38.25   \n",
      "566                 0.05648  ...        18.980          34.12   \n",
      "567                 0.07016  ...        25.740          39.42   \n",
      "568                 0.05884  ...         9.456          30.37   \n",
      "\n",
      "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
      "0             184.60      2019.0           0.16220            0.66560   \n",
      "1             158.80      1956.0           0.12380            0.18660   \n",
      "2             152.50      1709.0           0.14440            0.42450   \n",
      "3              98.87       567.7           0.20980            0.86630   \n",
      "4             152.20      1575.0           0.13740            0.20500   \n",
      "..               ...         ...               ...                ...   \n",
      "564           166.10      2027.0           0.14100            0.21130   \n",
      "565           155.00      1731.0           0.11660            0.19220   \n",
      "566           126.70      1124.0           0.11390            0.30940   \n",
      "567           184.60      1821.0           0.16500            0.86810   \n",
      "568            59.16       268.6           0.08996            0.06444   \n",
      "\n",
      "     worst concavity  worst concave points  worst symmetry  \\\n",
      "0             0.7119                0.2654          0.4601   \n",
      "1             0.2416                0.1860          0.2750   \n",
      "2             0.4504                0.2430          0.3613   \n",
      "3             0.6869                0.2575          0.6638   \n",
      "4             0.4000                0.1625          0.2364   \n",
      "..               ...                   ...             ...   \n",
      "564           0.4107                0.2216          0.2060   \n",
      "565           0.3215                0.1628          0.2572   \n",
      "566           0.3403                0.1418          0.2218   \n",
      "567           0.9387                0.2650          0.4087   \n",
      "568           0.0000                0.0000          0.2871   \n",
      "\n",
      "     worst fractal dimension  \n",
      "0                    0.11890  \n",
      "1                    0.08902  \n",
      "2                    0.08758  \n",
      "3                    0.17300  \n",
      "4                    0.07678  \n",
      "..                       ...  \n",
      "564                  0.07115  \n",
      "565                  0.06637  \n",
      "566                  0.07820  \n",
      "567                  0.12400  \n",
      "568                  0.07039  \n",
      "\n",
      "[569 rows x 30 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a3b304e6f04a028729170e48f649d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/01 17:23:19 INFO mlflow.store.artifact.artifact_repo: The progress bar can be disabled by setting the environment variable MLFLOW_ENABLE_ARTIFACTS_PROGRESS_BAR to false\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docker build --platform=linux/amd64 -f ./Dockerfile -t quay.io/foundry_model:17 .\n",
      "docker push quay.io/foundry_model:17 \n",
      "docker run quay.io/foundry_model:17\n",
      "\n",
      "\n",
      "File created at /tmp/local_models/foundry_model/v17/Dockerfile\n",
      "docker build --platform=linux/amd64 -f ./Dockerfile -t quay.io/foundry_model:17 .\n",
      "docker push quay.io/foundry_model:17 \n",
      "docker run quay.io/foundry_model:17\n",
      "\n",
      "\n",
      "File created at /tmp/local_models/foundry_model/v17/create_image.sh\n",
      "Model name foundry_model, and version 17 made prediction [0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 1 0 0 0 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 1\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 1 1 1 0 0 1 1\n",
      " 1 0 1 0 1 1 1 0 0 1 1 0 1 1 0 0 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 0 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 0 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1] for data      mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
      "0                   0.07871  ...        25.380          17.33   \n",
      "1                   0.05667  ...        24.990          23.41   \n",
      "2                   0.05999  ...        23.570          25.53   \n",
      "3                   0.09744  ...        14.910          26.50   \n",
      "4                   0.05883  ...        22.540          16.67   \n",
      "..                      ...  ...           ...            ...   \n",
      "564                 0.05623  ...        25.450          26.40   \n",
      "565                 0.05533  ...        23.690          38.25   \n",
      "566                 0.05648  ...        18.980          34.12   \n",
      "567                 0.07016  ...        25.740          39.42   \n",
      "568                 0.05884  ...         9.456          30.37   \n",
      "\n",
      "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
      "0             184.60      2019.0           0.16220            0.66560   \n",
      "1             158.80      1956.0           0.12380            0.18660   \n",
      "2             152.50      1709.0           0.14440            0.42450   \n",
      "3              98.87       567.7           0.20980            0.86630   \n",
      "4             152.20      1575.0           0.13740            0.20500   \n",
      "..               ...         ...               ...                ...   \n",
      "564           166.10      2027.0           0.14100            0.21130   \n",
      "565           155.00      1731.0           0.11660            0.19220   \n",
      "566           126.70      1124.0           0.11390            0.30940   \n",
      "567           184.60      1821.0           0.16500            0.86810   \n",
      "568            59.16       268.6           0.08996            0.06444   \n",
      "\n",
      "     worst concavity  worst concave points  worst symmetry  \\\n",
      "0             0.7119                0.2654          0.4601   \n",
      "1             0.2416                0.1860          0.2750   \n",
      "2             0.4504                0.2430          0.3613   \n",
      "3             0.6869                0.2575          0.6638   \n",
      "4             0.4000                0.1625          0.2364   \n",
      "..               ...                   ...             ...   \n",
      "564           0.4107                0.2216          0.2060   \n",
      "565           0.3215                0.1628          0.2572   \n",
      "566           0.3403                0.1418          0.2218   \n",
      "567           0.9387                0.2650          0.4087   \n",
      "568           0.0000                0.0000          0.2871   \n",
      "\n",
      "     worst fractal dimension  \n",
      "0                    0.11890  \n",
      "1                    0.08902  \n",
      "2                    0.08758  \n",
      "3                    0.17300  \n",
      "4                    0.07678  \n",
      "..                       ...  \n",
      "564                  0.07115  \n",
      "565                  0.06637  \n",
      "566                  0.07820  \n",
      "567                  0.12400  \n",
      "568                  0.07039  \n",
      "\n",
      "[569 rows x 30 columns]\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/base.py:443: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.client import MlflowClient\n",
    "# Create a Dockerfile \n",
    "import string\n",
    "\n",
    "def create_file_from_template(template_string, context, output_file_path):\n",
    "    # Create a Template object\n",
    "\n",
    "    template = string.Template(template_string)\n",
    "    \n",
    "    # Substitute placeholders with actual values\n",
    "    content = template.substitute(context)\n",
    "    print(content)\n",
    "    # Write the content to a file\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "    \n",
    "    print(f\"File created at {output_file_path}\")\n",
    "\n",
    "def predict(model_uri,features):\n",
    "    loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "    return loaded_model.predict(features)\n",
    "    \n",
    "def download_and_test(model_versions_to_build,base_path='/tmp/local_models'):\n",
    "    client = MlflowClient()\n",
    "    for mv in model_versions_to_build:\n",
    "        #mv = client.get_model_version(model_name, model_version)\n",
    "        run_id = mv.run_id\n",
    "        model_name = mv.name\n",
    "        model_version = mv.version\n",
    "        #An example path that exists on every machine. Modify as needed\n",
    "        model_download_path=f'{base_path}/{model_name}/v{model_version}'\n",
    "        os.makedirs(model_download_path,exist_ok=True)\n",
    "    \n",
    "        #Download artifacts and verify if they exist\n",
    "        client.download_artifacts(run_id,f\"\",model_download_path)\n",
    "        os.listdir(model_download_path)\n",
    "        #Resolve files\n",
    "        context = {\n",
    "            'FOUNDRY_URL': mv.tags['FOUNDRY_URL'],\n",
    "            'model_name': model_name,\n",
    "            'model_version': model_version,\n",
    "            'model_download_folder':  model_download_path,\n",
    "            'model_folder': mv.tags['MODEL_FOLDER'],\n",
    "            'model_client_folder':  mv.tags['MODEL_CLIENT_FOLDER'],\n",
    "            'entry_point': mv.tags['MODEL_ENTRY_POINT'],\n",
    "            'command_line': mv.tags['MODEL_EXECUTE_PATH']\n",
    "        }\n",
    "\n",
    "        with open(f\"{model_download_path}/create_docker.sh.template\", 'r') as file:\n",
    "           content = file.read()\n",
    "           output_file = f\"{model_download_path}/Dockerfile\"\n",
    "           create_file_from_template(content, context, output_file)\n",
    "        with open(f\"{model_download_path}/create_docker.sh.template\", 'r') as file:\n",
    "           content = file.read()\n",
    "           output_file = f\"{model_download_path}/create_image.sh\"\n",
    "           create_file_from_template(content, context, output_file)\n",
    "        client_folder = mv.tags['MODEL_CLIENT_FOLDER']\n",
    "        #Load the model and predict\n",
    "        d = pd.read_json(f'{model_download_path}/{client_folder}/features.json', orient='records', lines=True)\n",
    "        model_uri_saved = f'{model_download_path}/mymodel'\n",
    "        p = predict(model_uri_saved,d)\n",
    "        print(f'Model name {mv.name}, and version {mv.version} made prediction {p} for data {d}')\n",
    "\n",
    "\n",
    "client = MlflowClient()\n",
    "lst = mlflow.search_registered_models()\n",
    "model_versions_to_build=[]\n",
    "for m in lst:\n",
    "    name = m.name    \n",
    "    versions = m.latest_versions\n",
    "    total_versions = 0\n",
    "    if versions and len(versions)>0:\n",
    "        latest_version = m.latest_versions[0]\n",
    "        total_versions = latest_version.version\n",
    "        for i in range(1,int(total_versions)+1):\n",
    "            v = client.get_model_version(name,i)\n",
    "            if 'PUBLISH_TO_FOUNDRY' in v.tags and v.tags['PUBLISH_TO_FOUNDRY'] :                \n",
    "                model_versions_to_build.append(v)\n",
    "            #This if of type ModelVersion - See MLFLOW API\n",
    "\n",
    "\n",
    "\n",
    "print(download_and_test(model_versions_to_build))\n",
    "\n",
    "\n",
    "\n",
    "with open(\"/mnt/export-example/create_docker.sh.template\", 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "context = {\n",
    "    'FOUNDRY_URL': 'quay.io',\n",
    "    'model_name': 'test',\n",
    "    'model_version': '1',\n",
    "}\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = 'create_image.sh'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bead7042-8cb6-457a-a826-a82328f3a157",
   "metadata": {},
   "source": [
    "### Or run from the command line\n",
    "\n",
    "```\n",
    "export MODEL_NAME=foundry_model\n",
    "export MODEL_VERSION=7\n",
    "/tmp/local_models/${MODEL_NAME}/v${MODEL_VERSION}/example-prediction-code\n",
    "python example_predict.py foundry_model 7\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b5309b-889e-4b05-9112-95bd39a01421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dockerfile \n",
    "import string\n",
    "\n",
    "with open(\"/mnt/export-example/Dockerfile_Template\", 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "\n",
    "def create_file_from_template(template_string, context, output_file_path):\n",
    "    # Create a Template object\n",
    "\n",
    "    template = string.Template(template_string)\n",
    "    \n",
    "    # Substitute placeholders with actual values\n",
    "    content = template.substitute(context)\n",
    "    print(content)\n",
    "    # Write the content to a file\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write(content)\n",
    "    \n",
    "    print(f\"File created at {output_file_path}\")\n",
    "\n",
    "# Define the context for substitution\n",
    "context = {\n",
    "    'model_name': 'm_name',\n",
    "    'model_version': '1',\n",
    "    'model_download_folder': '/tmp/test',\n",
    "    'model_folder': 'mymodel',\n",
    "    'model_client_folder': 'client',\n",
    "    'entry_point': 'python',\n",
    "    'command_line': 'client/execute_model.py'\n",
    "}\n",
    "            'model_folder': mv.tags['MODEL_FOLDER'],\n",
    "            'model_client_folder':  mv.tags['MODEL_CLIENT_FOLDER'],\n",
    "            'entry_point': mv.tags['MODEL_ENTRY_POINT'],\n",
    "            'command_line': mv.tags['MODEL_EXECUTE_PATH']\n",
    "# Specify the output file path\n",
    "output_file_path = 'Dockerfile'\n",
    "\n",
    "# Create the file from the template\n",
    "create_file_from_template(content, context, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "11031c9e-46df-43a0-b559-4584525e2a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOUNDRY_URL=\"\"\n",
      "docker build --platform=linux/amd64 -f ./Dockerfile -t quay.io/test:1 .\n",
      "docker push quay.io/test:1 \n",
      "docker run quay.io/test:1\n",
      "\n",
      "\n",
      "File created at create_image.sh\n"
     ]
    }
   ],
   "source": [
    "# Create a Dockerfile \n",
    "import string\n",
    "\n",
    "with open(\"/mnt/export-example/create_docker.sh.template\", 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "context = {\n",
    "    'FOUNDRY_URL': 'quay.io',\n",
    "    'model_name': 'test',\n",
    "    'model_version': '1',\n",
    "}\n",
    "\n",
    "# Specify the output file path\n",
    "output_file_path = 'create_image.sh'\n",
    "\n",
    "# Create the file from the template\n",
    "create_file_from_template(content, context, output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c62e3b9-b8c2-42fc-8af7-31543ba4addc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
